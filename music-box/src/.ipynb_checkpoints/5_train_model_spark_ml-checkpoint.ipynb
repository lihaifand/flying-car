{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hli/anaconda/envs/carnd-term1/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Music\").getOrCreate()\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Path does not exist: file:/Users/hli/Dropbox/Turner/Tools/DS/DS501/HW/capstone/Capstone_Music_Box_Spark/music-box/data/df_model_final.csv;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o32.csv.\n: org.apache.spark.sql.AnalysisException: Path does not exist: file:/Users/hli/Dropbox/Turner/Tools/DS/DS501/HW/capstone/Capstone_Music_Box_Spark/music-box/data/df_model_final.csv;\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:360)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:348)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:344)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:348)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:533)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-10430aea0d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/df_model_final.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Path does not exist: file:/Users/hli/Dropbox/Turner/Tools/DS/DS501/HW/capstone/Capstone_Music_Box_Spark/music-box/data/df_model_final.csv;'"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('../data/df_model_final.csv',header=True,inferSchema=True).cache()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = df.columns\n",
    "selected_features.remove('uid')\n",
    "selected_features.remove('label')\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=selected_features,\n",
    "    outputCol=\"features\")\n",
    "data = assembler.transform(df).select('label', 'features')\n",
    "\n",
    "# train test split\n",
    "(train, test) = data.randomSplit([0.7, 0.3], seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.maxIter, [10, 20, 30, 40]) \\\n",
    "    .addGrid(lr.regParam, [0.3, 0.1, 0.01]) \\\n",
    "    .build()\n",
    "    \n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4) \n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "print('The best maxIter: {}'.format(cvModel.bestModel._java_obj.getMaxIter()))\n",
    "print('The best regParam: {}'.format(cvModel.bestModel._java_obj.getRegParam()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, pandas as pd, numpy as np\n",
    "%matplotlib inline\n",
    "lrCoeffs = pd.DataFrame(list(zip(selected_features, cvModel.bestModel.coefficients)), columns = ['feature', 'coeff']).sort_values(by=\"coeff\", ascending=False)\n",
    "ax =  lrCoeffs.plot.barh(figsize=(8, 10))\n",
    "t = np.arange(lrCoeffs.shape[0])\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(lrCoeffs['feature'])\n",
    "ax.set_title(\"Coefficient of Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### predict and evaluate performance\n",
    "\n",
    "# Predict train data\n",
    "predictions_train = cvModel.transform(train)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_train.select(\"probability\",\"prediction\", \"label\", \"features\").show(5)\n",
    "res_train = predictions_train.select(\"probability\",\"prediction\", \"label\").toPandas()\n",
    "\n",
    "\n",
    "# Predict test data\n",
    "predictions_test = cvModel.transform(test)\n",
    "res_test = predictions_test.select(\"probability\",\"prediction\", \"label\").toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# helper\n",
    "def plot_roc_curve(y_train, y_train_pred, y_test, y_test_pred):\n",
    "    \"\"\"\n",
    "    Plot ROC curves for the training set and the test set\n",
    "    \"\"\"\n",
    "    roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr_train, tpr_train, color='green',\n",
    "             lw=lw, label='ROC Train (AUC = %0.4f)' % roc_auc_train)\n",
    "    plt.plot(fpr_test, tpr_test, color='darkorange',\n",
    "             lw=lw, label='ROC Test (AUC = %0.4f)' % roc_auc_test)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_cumulative_gains(lift: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plot cumulative gains \n",
    "    Reference: https://analyticsgyanblog.wordpress.com/category/lift-curve/\n",
    "    http://www2.cs.uregina.ca/~dbd/cs831/notes/lift_chart/lift_chart.html\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    handles = []\n",
    "    handles.append(ax[0].plot(lift['numCases'], lift['TP'], 'r-', label='gains'))\n",
    "    handles.append(ax[0].plot(lift['numCases'], lift['randP'], 'b-', label='baseline'))\n",
    "    ax[0].set_xlabel('Number of Cases')\n",
    "    ax[0].set_ylabel('Gains')\n",
    "    ax[0].legend()\n",
    "    ax[0].set_title('Cumulative Gain Chart')\n",
    "    fig.show()\n",
    "    \n",
    "    ax[1].plot(lift['proportionOfCases'], lift['lift'], 'r-', label='lift curve')\n",
    "    ax[1].plot(lift['proportionOfCases'], lift['baseline'], 'b-', label='baseline')\n",
    "    ax[1].set_ylabel('Lift Curve')\n",
    "    ax[1].set_xlabel('Cumulative Proportion of Cases')\n",
    "    ax[1].set_title('Lift Chart')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def calc_cumulative_gains(df: pd.DataFrame, actual_col: str, predicted_col:str, probability_col:str):\n",
    "    \"\"\"\n",
    "    Generate the performance chart plot gains and lift\n",
    "    Reference: https://stackoverflow.com/questions/42699243/how-to-build-a-lift-chart-a-k-a-gains-chart-in-python\n",
    "    \"\"\"\n",
    "    lift = df.sort_values(by=probability_col, ascending=False)\n",
    "    numChurn = sum(lift[actual_col] == True)\n",
    "    numCases = lift.shape[0]\n",
    "    randProb = numChurn / numCases\n",
    "    lift['numCases'] = range(1, numCases+1)\n",
    "    # Gain Chart\n",
    "    lift['TP'] = lift[actual_col].cumsum()\n",
    "    lift['randP'] = randProb\n",
    "    lift['randP'] = lift['randP'].cumsum()\n",
    "    # Lift Chart\n",
    "    lift['proportionOfChurnCaptured'] = lift['TP'] / numChurn\n",
    "    lift['proportionOfCases'] = lift['numCases'] / numCases\n",
    "    lift['lift'] = lift['proportionOfChurnCaptured'] / lift['proportionOfCases']\n",
    "    lift['baseline'] = 1\n",
    "    plot_cumulative_gains(lift)\n",
    "    return lift    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for the training set and the test set\n",
    "y_train = res_train['label']\n",
    "res_train['probability'] = [v[1] for v in res_train['probability']]\n",
    "y_train_pred = res_train['probability']\n",
    "y_test = res_test['label']\n",
    "res_test['probability'] = [v[1] for v in res_test['probability']]\n",
    "y_test_pred = res_test['probability']\n",
    "\n",
    "plot_roc_curve(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_gain = calc_cumulative_gains(res_test, 'label',\"prediction\", \"probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\"\n",
    "                            ,featureSubsetStrategy=\"auto\"\n",
    "                            ,impurity='gini'\n",
    "                            ,maxDepth=20\n",
    "                            ,minInstancesPerNode=10\n",
    "                            ,maxBins=16\n",
    "                            , seed=42\n",
    "                            )\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50, 100, 150]) \\\n",
    "    .build()\n",
    "    \n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4) \n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "print('The best numTrees: {}'.format(cvModel.bestModel._java_obj.getNumTrees()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfImp = pd.DataFrame(list(zip(selected_features, cvModel.bestModel.featureImportances.toArray())), columns = ['feature', 'imp']).sort_values(by=\"imp\", ascending=False)\n",
    "ax =  rfImp.plot.barh(figsize=(8, 10))\n",
    "t = np.arange(rfImp.shape[0])\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(rfImp['feature'])\n",
    "ax.set_title(\"RF: feature importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### predict and evaluate performance\n",
    "\n",
    "# Predict train data\n",
    "predictions_train = cvModel.transform(train)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_train.select(\"probability\",\"prediction\", \"label\", \"features\").show(5)\n",
    "res_train = predictions_train.select(\"probability\",\"prediction\", \"label\").toPandas()\n",
    "\n",
    "\n",
    "# Predict test data\n",
    "predictions_test = cvModel.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_test.select(\"probability\",\"prediction\", \"label\", \"features\").show(5)\n",
    "res_test = predictions_test.select(\"probability\",\"prediction\", \"label\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for the training set and the test set\n",
    "y_train = res_train['label']\n",
    "res_train['probability'] = [v[1] for v in res_train['probability']]\n",
    "y_train_pred = res_train['probability']\n",
    "y_test = res_test['label']\n",
    "res_test['probability'] = [v[1] for v in res_test['probability']]\n",
    "y_test_pred = res_test['probability']\n",
    "\n",
    "plot_roc_curve(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gain = calc_cumulative_gains(res_test, 'label',\"prediction\", \"probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", seed=42)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20, 50, 100]) \\\n",
    "    .addGrid(gbt.maxDepth, [2, 3, 4]) \\\n",
    "    .build()\n",
    "    \n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4) \n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "print('The best maxIter: {}'.format(cvModel.bestModel._java_obj.getMaxIter()))\n",
    "print('The best maxDepth: {}'.format(cvModel.bestModel._java_obj.getMaxDepth()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfImp = pd.DataFrame(list(zip(selected_features, cvModel.bestModel.featureImportances.toArray())), columns = ['feature', 'imp']).sort_values(by=\"imp\", ascending=False)\n",
    "ax =  rfImp.plot.barh(figsize=(8, 10))\n",
    "t = np.arange(rfImp.shape[0])\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(rfImp['feature'])\n",
    "ax.set_title(\"GBT: feature importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### predict and evaluate performance\n",
    "\n",
    "# Predict train data\n",
    "predictions_train = cvModel.transform(train)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_train.select(\"probability\",\"prediction\", \"label\", \"features\").show(5)\n",
    "res_train = predictions_train.select(\"probability\",\"prediction\", \"label\").toPandas()\n",
    "\n",
    "\n",
    "# Predict test data\n",
    "predictions_test = cvModel.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_test.select(\"probability\",\"prediction\", \"label\", \"features\").show(5)\n",
    "res_test = predictions_test.select(\"probability\",\"prediction\", \"label\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for the training set and the test set\n",
    "y_train = res_train['label']\n",
    "res_train['probability'] = [v[1] for v in res_train['probability']]\n",
    "y_train_pred = res_train['probability']\n",
    "y_test = res_test['label']\n",
    "res_test['probability'] = [v[1] for v in res_test['probability']]\n",
    "y_test_pred = res_test['probability']\n",
    "\n",
    "plot_roc_curve(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gain = calc_cumulative_gains(res_test, 'label',\"prediction\", \"probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test.to_csv('res_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gain.to_csv('gain.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
